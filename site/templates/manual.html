{% extends "base.html" %}
{% block title %}VideoProcessor - Manual{% endblock %}
{% block main %}

<main class="container">
    <div class="p-4 p-md-5 mb-4 rounded bg-dark">
        <div class="col-md-12">
            <h1 class="display-4 text-white ">Manual</h1>
            <p>
                This is the VideoProcessor manual; it can be read as-is to get an in-depth understanding of VideoProcessor. 
                Alternatively, you'll find <img src="/static/images/questionmark_13.png" /> icons in the GUI, clicking these
                will take you to the topics here.
            </p>

            <!-- Capture input -->
            <p class="lead my-3" style="color: #FED700;">Capture input.</p>
            <p>
                The graphics pipeline of VideoProcessor starts with getting frames (both audio and video) from the wire, which generally will be HDMI.
                Schematically the relevant components look like the following:
            </p>
            <img src="/static/images/manual/capture_card_io.png" />
            <p>
                Data comes in on an interface on a capture card. 
                After capture the card will forward it to the application.

                This pipeline is reflected in the GUI in a vertical manner with the card and it's input at the top and from there on working
                down towards the captured video in the application. The following is an example input:
            </p>
            <div class="container">
                <div class="row">
                    <div class="col-3">
                        <img src="/static/images/manual/vp_capture_column.png" />
                    </div>

                    <div class="col">
                        <b>Capture device</b>
                        <ul>
                            <li>1) The selected capture card. If you have multiple capture cards there will be multiple entries here. It will default to the first available card.</li>
                            <li>2) The selected input port on your capture card. Most cards have more than one port. This will default to a port called HDMI.</li>
                            <li>3) The state of the capture, if this is "capturing" your card is reading from the HDMI wire. This does not mean that it's also getting valid input.</li>
                            <li>4) Additional capture card data. DeckLink users will want to see PCIe speed 2 and width >=4 here.</li>
                        </ul>

                        <b>Input</b>
                        <ul>
                            <li>5) If there is an input signal on the HDMI cable the card can recognize, locked will be Yes and the other fields will be populated.</li>
                            <li>6) This is the input resolution and frame rate</li>
                            <li>7) The input encoding and bit depth</li>
                            <li>8) Number of seen frames. V=Video, A=Audio. Miss are gaps in the stream were we would expect a frame but where none came.</li>
                        </ul>

                        <b>Captured video</b>
                        <ul>
                            <li>9) If VideoProcessor understands the format being output from your card valud will be Yes and the other fields will be populated.</li>
                            <li>10) Your video card's output does not need to be the same as it's input. The cards' firmware can encode it any way it wants/needs. This field will reflect how the data is represented in the software.</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Timing clock -->
            <p class="lead my-3" style="color: #FED700;">Timing clock.</p>
            <img src="/static/images/manual/vp_timing_clock.png" />
            <p>
                This displays which clock is used to timestamp the incoming frames.
                This will always use the best available clock, which is the capture card hardware clock.
                In order to understand how to set the frame offset you must understand the flow of time through VideoProcessor first. 
                The following image represents the timing domain, all components here are driven by the same clock coming from the capture card hardware.
            </p>
            <img src="/static/images/manual/clock_time_flow.png" />
            <p>
                The frame timestamp should ideally be just behind the VideoProcessor renderer.
                This gives the final renderer (DirectShow) some time to wait before it needs to accept the frame.
                The timestamp however is taken at the point where the frame entered the capture card; you can say that the capture timestamp is always "behind" from the clock as it was taken in the hardware before the process saw it.
            </p>
            <p>
                You can correct this forward to the point where it should be rendered with the offset. 9ms is about the time it takes for the hw to deliver the frame to the software. 90ms is about the time it takes to process everything.
                Auto here will monitor the latency in the system and will adjust accordingly (with a restart of the renderer which might be annoying).
            </p>

            <!-- HDR -->
            <p class="lead my-3" style="color: #FED700;">HDR.</p>
            <p>
                If the input is a High Dynamic Range (HDR) video signal the center column will display it's properties.
            </p>
            <div class="container">
                <div class="row">
                    <div class="col-4">
                        <img src="/static/images/manual/vp_hdr.png" />
                    </div>

                    <div class="col">
                        <b>Color space</b>
                        <p>
                            This is a <a class="text-white" href="https://en.wikipedia.org/wiki/CIE_1931_color_space">CIE 1931</a> colorspace diagram; the colored area represents what is visible to the human eye. 
                            Within it are drawn two triangle, which most of the time overlap so you only see one.
                            Well known coordinates in the color space are translated to human-readable names. <a class="text-white" href="https://en.wikipedia.org/wiki/Illuminant_D65">D65</a> for example means the ~6500K white point.
                        </p>
                        <ul>
                            <li>1) The black triangle represents the video container. This should always be >= the white triangle.</li>
                            <li>2) The white triangle represents the HDR metata, it is most often equal but can also be less than the video container.</li>
                        </ul>

                        <b>HDR Luminance</b>
                        <p>
                            These values relay information about the brightness of the frame and how it was seen during the mastering process.
                            More details <a class="text-white" href="https://www.mysterybox.us/blog/2016/10/19/hdr-video-part-3-hdr-video-terms-explained">here</a> and <a class="text-white" href="https://www.lightspace.lightillusion.com/uhdtv.html">here</a>.
                        </p>
                        <ul>
                            <li>3) Maximum Content Light Level (MaxCLL) represents the pixel light level in nits in whole movie.</li>
                            <li>4) Maximum Frame Average Light Level (MaxFALL) represents the maximum average light level of a frame in nits.</li>
                            <li>5) Min and max light levels of the display user for mastering the movie.</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Latency -->
            <p class="lead my-3" style="color: #FED700;">Latency.</p>
            <p>
                It takes time for video frames to move through the system and into the final renderer. This time we call latency. There are 3 points in the system where this time is sampled.
            </p>
            <img src="/static/images/manual/latency.png" />
            <p>
                This is represented in the GUI in the latency group:
            </p>
            <div class="container">
                <div class="row">
                    <div class="col-4">
                        <img src="/static/images/manual/vp_latency.png" />
                    </div>

                    <div class="col">
                        <ul>
                            <li>1) The time it took from the hardware capture to arrival in the videoprocessor process</li>
                            <li>2) The time it took from the hardware capture to arrival at the first part of the renderer, the queue. Plus the frame offset (which is negative). This should be well below zero</li>
                            <li>
                                3) The time it took from the hardware capture to handoff to the rendere. 
                                Plus the frame offset (which is negative). 
                                This should always be just below zero for best results, as that means it's to be rendered slighty in the future. 
                                This little bit of time is all that the renderer needs to ensure that the frame is played at exactly the right point in time.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- Renderer -->
            <p class="lead my-3" style="color: #FED700;">Renderer.</p>
            <p>
                The renderer is the component which takes the video stream from the capture card and turns it into visible pixels.
                VideoProcessor supports multiple renderers from different technologies, right now it only supports DirectShow renderers but the plan is to extend that to other frameworks.
            </p>
            <img src="/static/images/manual/vp_render.png" /><br /><br />

            <b>Renderer selection and lifetime</b>
            <ul>
                <li>1) This is the renderer to use. This list is auto-populated from operating system on a name basis, it is possible that VideoProcessor will show non-functional renderers.</li>
                <li>2) Restart forces a total restart of the renderer, removing it entirely and starting it up again. Generally this is not needed.</li>
                <li>3) Reset stops, clears and starts the renderer. This can help in removing queues in DirectShow renderers. This is very fast.</li>
                <li>4) Auto reset will reset automatically once in a while if the queue is too large. Given that this generally only is a startup problem there will be no more resets after the beginning.</li>
                <li>5) The party button.</li>
            </ul>

            <b>Timestamp</b>
            <ul>
                <li>
                    <p>6) Determines how frames are timestamped.</p>
                    <ul>
                        <li>
                            Clock-theo: Will just add the theoretical time to the start timestamp. 
                            That does not perfectly align with the timestamps (resolution difference and real-world clock wobble) and hence there will be a little bit of non-frame time.
                            This is the recommended mode.
                        </li>
                        <li>
                            Clock-clock: Will force a minimial queue of 2 and it'll take the start timestamp of the next frame as the stop timestamp of the current. 
                            This is the most pure way to do it as there is no non-frame time in the timestream and all frames line up perfectly.
                            In practice it leads to visual hickups.
                        </li>
                        <li>Theoretical: Just generates timestamps at a rate of the refresh rate</li>
                        <li>None: No timestamps, this will force the renderer to render immediately as this is an indicate it's too late.</li>
                    </ul>
                </li>
            </ul>

            <b>HDR overrides</b>
            <p>
                VideoProcessor cannot always perfectly determine what the HDR metadata is. 
                Or when you have a source which sends the right pixels but the wrong metadata. 
                For these cases you can use the overrides here.
            </p>
            <ul>
                <li>7) Nominal range override.</li>
                <li>8) Transfer function override.</li>
                <li>9) Transfer matrix override.</li>
                <li>10) Primaries override.</li>
            </ul>

            <b>State</b>
            <ul>
                <li>11) The state of the renderer. Only when this is Running will there be a picture.</li>
            </ul>

            <b>Queue</b>
            <ul>
                <li>12) If checked VideoProcessor will use a queue and a separate renderer thread to buffer frames between capture and renderer. If unchecked the capture will call the renderer directly, this will lead to major delays in DirectShow.</li>
                <li>13) This is the current queue size and the maximum queue size. If the queue gets bigger than the maximum the oldest frame is dropped. You want your queue to always be around 0-2. Anything more means you should press reset.</li>
                <li>14) Drop count for frames which were not shown.</li>
            </ul>

            <!-- Keyboard shortcuts -->
            <p class="lead my-3" style="color: #FED700;">Keyboard shortcuts.</p>
            <p>
                The following shortcuts are hardcoded into VideoProcessor. Any other key combination or press is forwarded to the renderer.
            </p>
            <ul>
                <li>ALT+F4: Exit process</li>
                <li>ALT+Enter: Toggle full screen</li>
                <li>ESC: Exit full screen</li>
                <li>Enter: Context dependent if you're in an input box it'll do what is needed. Default is to restart the renderer.</li>
            </ul>

        </div>
    </div>
</main>

{% endblock %}
